Позначка часу,Група,"Припустим, що ми навчили логістичну регресію. На новому прикладі х вона видає результат hθ(x)=0.4. Це означає (оберіть ВСІ релевантні варіанти)",Припустимо для навчальної множини використовується класифікатор логістичної регресії hθ(x) з двома ознаками. Оберіть всі коректні твердження ,Яку проблему вирішує сингулярний розклад матриці?,Масштабування даних - це,"Для логістичної регресії градієнт обчислюється за формулою. Які із формул коректно описують модифікацію вагових коефіцієнтів логістичної регресії, якщо коефіцієнт швидкості навчання рівний α. Оберіть всі можливі варіанти. ",Оберіть всі вірні твердження,Unnamed: 16,Припустимо для навчальної множини використовується класифікатор логістичної регресії hθ(x) з двома ознаками. Оберіть всі коректні твердження .1,Unnamed: 18,Оберіть на картинках всі приклади переначання моделі на навчальних даних,Оберіть на картинках всі приклади недоначання моделі на навчальних даних,Які із тверджень вірні щодо навчання логістичної регресії?,Які проблеми виникають при навчанні багатофакторної лінійної регресії з використанням нормальної системи рівнянь?,Побудувати модель класифікації на основі персептрона Розенблатта і описати функцію роздільної поверхні для обчислення логічної функції not(A&B). Навести приклади обчислення значень цієї функції. 
03.11.2023 11:24:21,ФІ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Жодних проблем,Спосіб попередньої обробки даних в аналізі даних,"для всіх j, Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",A,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,A,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Всі прераховані, Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1bSjC4m1R0HljrvL3GACFFAj3T-WqjbH1
03.11.2023 12:03:38,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Мультиколеніарність,https://drive.google.com/open?id=1yE-g39klRWrzpp8ki6t5rfOeRubzkGAx
03.11.2023 12:15:17,ФБ-04,"P(y=1|x;θ)=0.4, P(y=1|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Мультиколеніарність,https://drive.google.com/open?id=19HOi30ZyHAnafKG1e_T0IWLUZZWRMvWq
03.11.2023 12:45:09,ФБ-04,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1n_9QHjJfZTYoJRrROe9M6slM2Ob-Fa3I
03.11.2023 12:48:03,ФБ-05,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,для всіх j одночасно,"Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",B,A,D,Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",
03.11.2023 12:57:14,ФІ-01,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1lp_1cbRS4-dOR8vHkKBZIcNIobvFESRO
03.11.2023 13:03:22,ФІ-01,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1G-duZBqFanKGzcu2FycIMZM_XUNfrJ9Q
03.11.2023 13:16:42,ФІ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Перенавчання персептрона,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",D,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=15PlEYfQZpG0VDPMSNcHFdD7wFNC0kU27
03.11.2023 13:23:50,FI-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Перенавчання персептрона,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",D,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1Xn8bmOioCJVrWSJA1nF2nLdph1i0owIB
03.11.2023 13:27:28,ФБ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=12dPDKjtNpdrW93eLMk6cgt_PdF2QI5M0
03.11.2023 13:41:02,ФБ-06,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1wNmafbeXUjBRLu6EAbXPLJMzGbGOf8z_
03.11.2023 13:57:31,ФБ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=17DLhokxTG20jJtadvu3VIrafge3z4eAm
03.11.2023 14:04:27,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Мультиколеніарність,https://drive.google.com/open?id=1mHkelz0mNEC72Mkoh90LtNBtwCBUWNv1
03.11.2023 14:10:03,ФБ-05,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, При збільшенні кількості ітерацій навчання можливо hθ(x)>1, Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,Одночасно для всіх j,"Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",D,"C, B","D, A","Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних, Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",
03.11.2023 14:44:23,ФБ-04,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4",Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",D,D,"A, C, B","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1rJmTfM49Jdo6iWu-dfuUn3b3djfLDHG4
03.11.2023 14:56:45,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",A,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",D,"D, C","B, A","Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1Gx474JMlbLLf-jAw60qFKXl7Dp4zGaFz
03.11.2023 15:35:36,ФІ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1e7ucEJ0wjkHYkQlh3cZZ-EHNTvJh8UIX
03.11.2023 15:47:26,ФІ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=11auRYCZlz1ExHwNl19TKdL0GcFt2AZKe
03.11.2023 15:53:24,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1UcD8ZXi53scxQg86dTGX1y27PyklVb27
03.11.2023 16:28:05,ФІ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",D,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",C,A,D,"Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1nWqI3WoNh_kH7ESaMPkuWfQ8274bPA9x
03.11.2023 16:44:18,ФБ-06,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1drEdK0jW_HIRwZLhckVDetSvVe_YPezA
03.11.2023 16:46:33,ФІ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Жодних проблем,Спосіб попередньої обробки даних в аналізі даних,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",A,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,A,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1XJpySxnafOcr2RNIwbczxGwHvs4f9y_l
03.11.2023 17:03:22,ФБ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1hTSKEm0SHp8UasGXHynDoexzYk14gC94
03.11.2023 17:09:41,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Стандартизація,"Одночасно для всіх j, Варіант 2","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",A,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",A,"B, A","D, C","Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Погана обумовленість матриці, Сингулярний розклад, Мультиколеніарність, Всі прераховані",https://drive.google.com/open?id=1AYT9yuRtpfouUNJnAFMD9KUFZBprWJKM
03.11.2023 17:13:02,ФІ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Жодних проблем,Приведення даних до заданого діапазону,для всіх j,"Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",D,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",A,"B, A",D,"Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання",Всі прераховані,https://drive.google.com/open?id=1LlrwWjnSvp-ah8mcyzpRu-JqiVCRdh8B
03.11.2023 17:19:30,ФІ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1tcvZ5qs0s8ocd9VzHDE8RSorFBqcCzTl
03.11.2023 17:19:54,ФІ-01 ,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1I0mFkIlUoUZjrSEw0w14hxa4ozZyPBL6
03.11.2023 17:35:32,ФБ-06,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1eyemxfG10T3FDP9bCoKnV6pq32aHhOGu
03.11.2023 17:54:09,ФБ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1ZqadAccnOnRIU9szdQUOMnvnufwWoDmk
03.11.2023 17:56:50,ФІ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1-c1sfc4Yh50Q5HHPGn2Zw58ok2fEgYEG
03.11.2023 18:35:01,ФБ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",D,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",C,A,"D, B","Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних",Всі прераховані,https://drive.google.com/open?id=1mFUytmCUKcGwsjJ_h4axRtpJ57KgDlQE
03.11.2023 18:36:35,ФБ-05,"P(y=1|x;θ)=0.6, P(y=0|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,C,"B, D","A, C",Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1kgV2ZCC1hWf-mwxrAVPUWexlIGtKrUgN
03.11.2023 18:45:38,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",A,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1iA-GAoFlfi5i4LAQnW1L9haC7ZYIGxKq
03.11.2023 19:03:06,ФБ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=143HyaLKkv_UXUx_FinhAmIwnPhHikArb
03.11.2023 19:05:39,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,D,"B, C, A","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1aKodN_CW2qCrxQT1AQgDmC4qfNXrWdS2
03.11.2023 19:15:11,ФБ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,"Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Погана обумовленість матриці, Сингулярний розклад, Мультиколеніарність",https://drive.google.com/open?id=1fcMtgjoao29adHAO0-fKAkg4x-abYGXM
03.11.2023 19:32:10,ФБ-06,"P(y=0|x;θ)=0.4, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання логістичної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно",Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0,B,Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних,A,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Всі прераховані,
03.11.2023 19:53:55,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",B,A,D,"Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1wORyj3hD1rfWKIhG7SrtVKFMUTjO_uMU
03.11.2023 19:54:12,ФІ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1APu3638deWJ0stGHSETYJ8jz4WSnpHzn
03.11.2023 19:59:07,ФБ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Всі прераховані,https://drive.google.com/open?id=1LpGo0-DccgYknx7nttimNUPNvY2i7KLr
03.11.2023 19:59:08,ФБ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання логістичної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",
03.11.2023 20:02:24,ФІ-02,P(y=1|x;θ)=0.4,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Перенавчання персептрона,Приведення даних до заданого діапазону,"Одночасно для всіх j, Варіант 2","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",D,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1nLDXOXx021YTooXh5tJ4bUOL_O-uYRw1
03.11.2023 20:16:50,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Мультиколеніарність, Погана обумовленість матриці",
03.11.2023 20:18:02,ФІ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",B,A,D,"Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1WSzJqA6JmG_n1kVUJJ-GM7JGAMXX3nsN
03.11.2023 20:23:47,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"D, A","C, B, A","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",
03.11.2023 20:24:06,ФБ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",
03.11.2023 20:24:53,ФБ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,для всіх j одночасно,"Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",C,D,"B, C, A",,"Мультиколеніарність, Погана обумовленість матриці",
03.11.2023 20:26:45,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",
03.11.2023 20:27:19,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1pe9lMyIElOuGCNEvSJbTULFQ_kXbAAfi
03.11.2023 20:36:11,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1BxdHZKgLJUUC483ysYGDp_vc9N1Gi9gw
03.11.2023 20:44:57,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"A, B",D,"Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1YtWVxBhkep88VeeST7VMoan-iLxBIOld
03.11.2023 20:47:02,ФБ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",B,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,C,A,D,Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1m3XrS0tgvf0YrEJ-PzoE-LjWCSKGrvas
03.11.2023 20:49:37,ФІ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",C,"Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,A,D,"Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1KrguRF28vK3f6bNH8j-A8v35USKOJDW0
03.11.2023 20:56:10,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання логістичної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1AEM6oRtiIG-o58s5_Wh85_irB5wMJx0M
03.11.2023 21:03:56,ФІ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",A,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1i0IinkyDLX-U0GxHI0CQJ0O7Rx1-XNk_
03.11.2023 21:07:08,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Варіант 2, для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних,B,"D, A","B, C","Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1jnYjqc7RylPm_H2FcdrAaEQKDNVYRo6M
03.11.2023 21:10:13,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Перенавчання персептрона,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j, Варіант 2","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",A,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,A,"B, A","C, D",Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1wSKZsdRGIImwAOPHj4pVASQzyzUL6-E2
03.11.2023 21:11:17,ФБ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=13ZQaS1korbP4UX-ZG1BjI5ueIVCPkrry
03.11.2023 21:15:29,ФБ-05,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",D,A,D,"Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Погана обумовленість матриці, Мультиколеніарність",
03.11.2023 21:23:18,ФБ-06,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Сингулярний розклад, Погана обумовленість матриці",https://drive.google.com/open?id=1ICCVbF8VdaapNLEirMqH2mzpyQpDoKcm
03.11.2023 21:24:32,ФБ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1WpLsU9_MCQHwccuvC7rpdxSn31s83oKO
03.11.2023 21:28:53,ФІ-03,"P(y=1|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",B,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,,"Жодних, Мультиколеніарність",https://drive.google.com/open?id=1ZxwuGGbtrqtWsAvmGCeSpENEbDw9nQHP
03.11.2023 21:37:41,ФБ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1uP965rw62p4THvMrlGC0kEIuonYit6x0
03.11.2023 21:42:00,ФБ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=18e1ppLQHYs6EpZnsHHL0cS9YvIwBbJJP
03.11.2023 21:44:16,ФБ-02 ,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1Aayj2wNovtfAOFBvifwiPQYmVxi9_bu9
03.11.2023 21:47:38,ФІ-02,"P(y=1|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Перенавчання персептрона,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,D,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1iEkxfK8Nb1NNXG9g5GQ9RmdlaGEzNILP
03.11.2023 21:50:02,ФБ-06,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,Одночасно для всіх j,Значення сигмоїдної функції ніколи не перевищує 1,B,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,C,A,D,"Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Погана обумовленість матриці, Мультиколеніарність",
03.11.2023 21:50:45,ФБ-04,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4",Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",D,C,"C, B, A","Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1HGjWvfQQrRLVrAqr1kjA39juQhHNzR6x
03.11.2023 21:53:21,ФБ-06,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,D,"A, B, C","Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1E_sBGINqJXO-Q_9_s9v8lLqhZyKAc-4M
03.11.2023 21:59:49,ФФ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",B,A,"B, D","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",
03.11.2023 22:07:13,ФБ-03,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1Sqmv_NStfmDeU2_AOCPc8TRA_sEieoAK
03.11.2023 22:08:01,ФІ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,"D, B",,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1WDzaV6tdl4pjDVFCSkm2U3-OReaTEfrb
03.11.2023 22:08:56,ФІ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"B, A",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1fmrtOAoxcGI5sjoHbjAkc9bc4W2o_TYU
03.11.2023 22:23:20,ФБ-04,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,D,"A, B, C","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=10962UMFbCrJclHj1o388tD1xQ-iXRuir
03.11.2023 22:24:06,ФБ-05,,"Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Стандартизація,Варіант 2,"Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",A,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",A,"B, A",D,"Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних",Всі прераховані,
03.11.2023 22:25:59,ФІ-03,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1hZXk72phGktk3nY2aO3UELDFPeMvzuxf
03.11.2023 22:26:14,ФБ-05,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Стандартизація,"Варіант 2, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",A,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",A,"C, B, A","D, C","Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Всі прераховані, Сингулярний розклад, Погана обумовленість матриці",
03.11.2023 22:27:15,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6",Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",D,D,"C, B","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=137N94cxLuY6ljdJlclIeKWNMyXuJCnxI
03.11.2023 22:31:01,ФБ-06 ,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j, Одночасно для всіх j","Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",A,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",D,D,"A, B, C","Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Мультиколеніарність, Сингулярний розклад",https://drive.google.com/open?id=10avJPcKfA1QPrLLkvsiD--gCYErbj5lH
03.11.2023 22:32:40,ФБ-05,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",A,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",C,"B, A","D, C",Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Всі прераховані,https://drive.google.com/open?id=1zcDz4Etu85M0CYkY0_xRlOxL4_7-2WgK
03.11.2023 22:35:16,ФБ-05,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",A,"Логістична регересія дозволить розділити класи, оскільки це нелінійна функція, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",C,"B, A","D, C",Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Всі прераховані,https://drive.google.com/open?id=1TtjGvOV-OjdtSnnnRDRsnT4AEHOA9vIz
03.11.2023 22:44:00,ФБ-04,,"При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,D,"C, B, A","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1KnsCxxpG-IvgcQ60CgZzxZFERedkVCN-
03.11.2023 22:45:19,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",A,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",C,"B, A","C, D",Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Всі прераховані,https://drive.google.com/open?id=16Br6-GXgr36xFecuTSCoW1jVHgJGcWhT
03.11.2023 22:46:18,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",A,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Логістична регересія дозволить розділити класи, оскільки це нелінійна функція",C,"B, A","C, D",Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,Всі прераховані,https://drive.google.com/open?id=1cGmzlDYF0prant35kA_ECLPoRfwcHoZm
03.11.2023 22:46:40,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,A,"C, D","Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нових ознак до моделі допоможе уникнути перенавчання","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1lOVuiFINeNPPc4t7MXYiAPc9gaNYQF0g
03.11.2023 23:04:57,ФІ-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,B,A,"D, C",Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=14b_l-zU3o80oJvjw5MaGXRowTxbjFkdr
03.11.2023 23:05:55,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"B, A",D,Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1Ke-17SM70kZuhADsMsvZKBa4IoQ9T6zK
03.11.2023 23:19:39,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Значення сигмоїдної функції ніколи не перевищує 1",D,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",A,D,C,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Мультиколеніарність, Погана обумовленість матриці, Сингулярний розклад",https://drive.google.com/open?id=1-ujfvVEV4nrzyxhFPjz8NQALQUC2nWiD
03.11.2023 23:25:42,ФФ-01,"P(y=0|x;θ)=0.4, P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.6, P(y=1|x;θ)=0.4","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0, При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Варіант 2, для всіх j, Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",B,A,D,"Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних, Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1XDZ3UDTUAT7qZ_biju-vy2aylX585pbM
03.11.2023 23:30:48,ФБ-02,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"A, B",D,Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних,"Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=12EyC394t8QXiXKkW2PBFjr6CjJxDskf1
03.11.2023 23:41:11,ФБ-02,"P(y=1|x;θ)=0.6, P(y=1|x;θ)=0.4","При додаванні властивостей вищих порядків значення функції втрат J(θ) збільшиться, оскільки збільшиться кількість доданків, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j, Одночасно для всіх j","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,"A, B",D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=1P8dCBdOPIn8yYA3jp8RCKPbJmsF2JfSg
03.11.2023 23:57:46,ФБ-04,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Для оптимального значення θ функція втрат J(θ)>=0",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,A,D,"Додавання параметру регуляризації завжди покращує роботу моделі на навчальних даних, Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних",Всі прераховані,https://drive.google.com/open?id=1PRu1aBgQIQEDTWSHm2FLUr2YPqRaYdtl
03.11.2023 23:57:51,ФБ-04,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4",Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних,Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"Одночасно для всіх j, для всіх j одночасно","Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Значення сигмоїдної функції ніколи не перевищує 1, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат",B,"A, B","D, C","Додавання нових ознак до моделі допоможе уникнути перенавчання, Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних","Погана обумовленість матриці, Мультиколеніарність",https://drive.google.com/open?id=16uPmMEN-lpPwV4dIwYcNxuYd4lIrva9H
04.11.2023 00:00:13,ФІ-02,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Спосіб попередньої обробки даних в аналізі даних,,"Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0, Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона",B,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",C,"A, B","D, C",,"Погана обумовленість матриці, Мультиколеніарність",
04.11.2023 16:53:08,ФБ-05,"P(y=1|x;θ)=0.4, P(y=0|x;θ)=0.6","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних, Додавання нової ознаки в модель завжди покращує роботу моделі на навчальних даних",D,A,D,"Додавання нової ознаки в модель не погіршує роботу моделі на навчальних даних, Додавання нової ознаки в модель завжди покращує роботу моделі на тестових даних","Мультиколеніарність, Погана обумовленість матриці",https://drive.google.com/open?id=1_1qqG7fYWY765iV-RVnH9SdOqHoTRYL5
05.11.2023 21:15:11,фе-01,"P(y=0|x;θ)=0.6, P(y=1|x;θ)=0.4","Для оптимального значення θ функція втрат J(θ)>=0, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",Навчання багатофакторної лінійної регресії,Приведення даних до заданого діапазону,"для всіх j одночасно, Одночасно для всіх j","Для логістичної регресії алгоритм градієнтного спуску може приводити в локальний мінімум. Для подолання цієї проблеми використовують методи оптимізації вищих порядків, наприклад метод Ньютона, Лінійну регресію можна використовувати для задач класифікації, якщо ввести поняття порогу, Значення сигмоїдної функції ніколи не перевищує 1, Значення функції втрат логістичної регресії після навчання хоча б на 1 прикладі завжди більше або рівне 0",C,"Класи не є лінійно роздільними, тому метод градієнтного спуску не знайде мінімум функції втрат, Додавання поліноміальних властивостей (членів вищих порядків) може підвищити точність опису навчальних даних",B,A,D,Додавання нових ознак до моделі допоможе уникнути перенавчання,"Мультиколеніарність, Погана обумовленість матриці",
